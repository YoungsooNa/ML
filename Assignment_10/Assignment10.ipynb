{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "file_data   = \"mnist.csv\"\n",
    "handle_file = open(file_data, \"r\")\n",
    "data        = handle_file.readlines()\n",
    "handle_file.close()\n",
    "\n",
    "size_row    = 28    # height of the image\n",
    "size_col    = 28    # width of the image\n",
    "\n",
    "num_image   = len(data)\n",
    "count       = 0     # count for the number of images\n",
    "\n",
    "#\n",
    "# normalize the values of the input data to be [0, 1]\n",
    "#\n",
    "def normalize(data):\n",
    "\n",
    "    data_normalized = (data - min(data)) / (max(data) - min(data))\n",
    "\n",
    "    return(data_normalized)\n",
    "\n",
    "#\n",
    "# make a matrix each column of which represents an images in a vector form\n",
    "#\n",
    "list_image  = np.empty((size_row * size_col, num_image), dtype=float)\n",
    "list_label  = np.empty(num_image, dtype=int)\n",
    "\n",
    "for line in data:\n",
    "\n",
    "    line_data   = line.split(',')\n",
    "    label       = line_data[0]\n",
    "    im_vector   = np.asfarray(line_data[1:])\n",
    "    # already normalized\n",
    "    im_vector   = normalize(im_vector)\n",
    "\n",
    "    list_label[count]       = label\n",
    "    list_image[:, count]    = im_vector\n",
    "\n",
    "    count += 1\n",
    "    \n",
    "#    \n",
    "# making a value of labels into one-hot encoded array\n",
    "#\n",
    "def one_hot_encoding(array, num):\n",
    "    new_list = []\n",
    "    for i in array:\n",
    "        temp_list = [0]*num\n",
    "        temp_list[i] = 1\n",
    "        new_list.append(temp_list)\n",
    "    \n",
    "    return new_list\n",
    "\n",
    "x_train = list_image[:, :1000]\n",
    "y_train = np.asarray(one_hot_encoding(list_label[:1000],10))\n",
    "\n",
    "x_val = list_image[:, 1000:]\n",
    "y_val = np.asarray(one_hot_encoding(list_label[1000:],10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 1000)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "x_train = torch.Tensor(x_train).to(device)\n",
    "y_train = torch.Tensor(y_train).to(device)\n",
    "\n",
    "x_val = torch.Tensor(x_val).to(device)\n",
    "y_val = torch.Tensor(y_val).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    a = 1 / (1 + torch.exp(-z))\n",
    "    return a\n",
    "\n",
    "def softmax(z):\n",
    "    exp_z = torch.exp(z)\n",
    "    return exp_z / torch.sum(exp_z, axis=1).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "x_train.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple = [784, 200, 10]\n",
    "feeling = [784, 1568, 784, 196, 49, 10]\n",
    "divide2 = [784, 392, 196, 98, 49, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN:\n",
    "    def __init__(self, architect, epochs=100, lr=0.1, l2=0, starting = 0, save_term = 50, model_name = 'fcn'):\n",
    "        # parameters\n",
    "        self.w = []\n",
    "        self.b = []\n",
    "        self.architect = architect\n",
    "        self.initialize(architect)\n",
    "        \n",
    "        # for calculate\n",
    "        self.a = [0]*(len(self.w)+1)\n",
    "        self.dw = [0]*len(self.w)\n",
    "        self.db = [0]*len(self.w)\n",
    "        \n",
    "        # log\n",
    "        self.loss_log = []\n",
    "        self.acc_log = []\n",
    "        self.val_loss_log = []\n",
    "        self.val_acc_log = []\n",
    "        \n",
    "        # hyper parameters\n",
    "        self.start_lr = lr\n",
    "        self.lr = lr\n",
    "        self.l2 = l2\n",
    "        self.epochs = epochs\n",
    "        \n",
    "        # ect\n",
    "        self.starting = starting\n",
    "        self.save_term = save_term\n",
    "        self.model_path = 'model/'\n",
    "        self.model_name = 'fcn'\n",
    "        self.last_saved_time = 0\n",
    "        np.random.seed(728)\n",
    "    \n",
    "    def initialize(self, architect):\n",
    "        for i in range(len(architect)-1):\n",
    "            self.w.append(torch.Tensor(np.random.normal(0, 1, (architect[i], architect[i+1]))).to(device))\n",
    "            self.b.append(torch.Tensor(np.zeros(architect[i+1])).to(device))\n",
    "    \n",
    "    def forpass(self, x):\n",
    "        z = x.t()\n",
    "        self.a[0] = z\n",
    "        for i in range(len(self.w)):\n",
    "            y = torch.mm(z, self.w[i]) + self.b[i]\n",
    "            z = sigmoid(y)\n",
    "            self.a[i+1] = z\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    def backprop(self, err):\n",
    "        m = len(self.a[0])\n",
    "        err_h = err\n",
    "        \n",
    "        for i in range(len(self.w)-1, 0, -1):\n",
    "            self.dw[i] = torch.mm(self.a[i].T, err_h)/ m\n",
    "            if i== len(self.w)-1:\n",
    "                self.db[i] = torch.sum(err_h) / m\n",
    "            else:\n",
    "                self.db[i] = torch.sum(err_h, axis=0) / m\n",
    "            \n",
    "            err_h = torch.mm(err_h, self.w[i].T ) * self.a[i] * ( 1 - self.a[i])\n",
    "    \n",
    "    def update(self, m):\n",
    "        for i in range(len(self.w)):\n",
    "            m = len(self.a[0])\n",
    "            self.dw[i] += self.l2 * self.w[i] / m\n",
    "            self.w[i] -= self.lr * self.dw[i]\n",
    "            self.b[i] -= self.lr * self.db[i]\n",
    "\n",
    "    def training(self, x, y):\n",
    "        m = len(x)\n",
    "        z = self.forpass(x)\n",
    "        a = softmax(z)\n",
    "        err = -(y - a)\n",
    "        self.backprop(err)\n",
    "        self.update(m)\n",
    "        \n",
    "        return a\n",
    "    \n",
    "    def fit(self, x, y, val_x, val_y):\n",
    "        m = len(x)\n",
    "        for k in range(self.epochs):\n",
    "            a = self.training(x, y)\n",
    "            a = torch.clamp(a, min=1e-10, max=1-1e-10)\n",
    "            \n",
    "            loss = torch.sum(-y*torch.log(a))\n",
    "            \n",
    "            z_v = self.forpass(x_val)\n",
    "            a_v = softmax(z_v)\n",
    "            a_v = torch.clamp(a_v, min=1e-10, max=1-1e-10)\n",
    "            \n",
    "            val_loss = torch.sum(-val_y*torch.log(a_v))\n",
    "            \n",
    "            l2_sum = 0\n",
    "            for i in range(len(self.w)):\n",
    "                l2_sum += self.l2 / 2 * torch.sum(self.w[i]**2)\n",
    "            \n",
    "            loss += l2_sum\n",
    "            val_loss += l2_sum\n",
    "            \n",
    "            acc = torch.argmax(a, axis=1) == torch.argmax(y, axis=1)\n",
    "            acc = torch.mean(acc.float())\n",
    "            val_acc = torch.argmax(a_v, axis=1) == torch.argmax(val_y, axis=1)\n",
    "            val_acc = torch.mean(val_acc.float())\n",
    "            \n",
    "            \n",
    "            self.loss_log.append(loss.item())\n",
    "            self.acc_log.append(acc.item())\n",
    "            self.val_loss_log.append(val_loss.item())\n",
    "            self.val_acc_log.append(val_acc.item())\n",
    "            \n",
    "            if (k+1) % self.save_term == 0:\n",
    "                self.last_saved_time = int(time.time())\n",
    "                self.save_model(k+1+self.starting, f\"{self.last_saved_time}_{self.model_name}_{k+1+self.starting}_{np.max(self.val_acc_log):>.8}\"  + \".pt\")\n",
    "                \n",
    "                \n",
    "    def save_model(self, epoch, name):\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'acc' : self.acc_log,\n",
    "            'loss': self.loss_log,\n",
    "            'val_loss' : self.val_loss_log,\n",
    "            'val_acc' : self.val_acc_log,\n",
    "            'w' : self.w,\n",
    "            'b' : self.b,\n",
    "            'lr': self.lr,\n",
    "            'l2': self.l2,\n",
    "        }, self.model_path + name)\n",
    "    \n",
    "    def load_model(self, name, new_epoch):\n",
    "        saved_model = torch.load(self.model_path + name)\n",
    "        self.starting = saved_model['epoch']\n",
    "        self.lr = saved_model['lr']\n",
    "        self.l2 = saved_model['l2']\n",
    "        self.w = saved_model['w']\n",
    "        self.b = saved_model['b']\n",
    "        self.acc_log = saved_model['acc']\n",
    "        self.loss_log = saved_model['loss']\n",
    "        self.val_acc = saved_model['val_acc']\n",
    "        self.val_loss = saved_model['val_loss']\n",
    "        self.epochs = new_epoch\n",
    "        \n",
    "                         \n",
    "                         \n",
    "                         \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_acc(fcn, save=False, name='', show=True):\n",
    "        plt.plot(np.squeeze(fcn.acc_log), color='b', label='train')\n",
    "        plt.plot(np.squeeze(fcn.val_acc_log), color='r', label='test')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('iterations ')\n",
    "        plt.legend()\n",
    "        plt.title(\"Learning rate =\" + str(fcn.lr)+\"  L2 =\" + str(fcn.l2) + \" model : \" + str(fcn.architect))\n",
    "        if save:\n",
    "            plt.savefig(name)\n",
    "        if show:\n",
    "            plt.show()\n",
    "        plt.cla()\n",
    "            \n",
    "        \n",
    "def draw_err(fcn, save=False, name='',show=True):\n",
    "        plt.plot(np.squeeze(fcn.loss_log), color='b', label='train')\n",
    "        plt.plot(np.squeeze(fcn.val_loss_log), color='r', label='test')\n",
    "        plt.ylabel('loss')            \n",
    "        plt.xlabel('iterations ')\n",
    "        plt.legend()\n",
    "        plt.title(\"Learning rate =\" + str(fcn.lr)+\"  L2 =\" + str(fcn.l2) + \" model : \" + str(fcn.architect))\n",
    "        if save:\n",
    "            plt.savefig(name)\n",
    "        if show:\n",
    "            plt.show()\n",
    "        plt.cla()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model : [784, 200, 10], lr:0.01, l2:0.001, best_acc = 0.31866667\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-304-8c476f26ebdf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0me_l2\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist_l2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mn1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFCN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_term\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me_l2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me_lr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m             \u001b[0mn1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"model : {e_model}, lr:{e_lr}, l2:{e_l2}, best_acc = {np.max(n1.val_acc_log):>.8}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mdraw_acc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf\"result/{n1.last_saved_time}_acc.png\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-302-602f7e0ec967>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, val_x, val_y)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_log\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macc_log\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mval_loss_log\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "simple = [784, 200, 10]\n",
    "feeling = [784, 1568, 784, 196, 49, 10]\n",
    "divide2 = [784, 392, 196, 98, 49, 10]\n",
    "\n",
    "list_models = [simple, feeling, divide2]\n",
    "list_lr = [0.01, 0.1, 0.005]\n",
    "list_l2 = [0.001, 0.01, 0.005]\n",
    "\n",
    "for e_model in list_models:\n",
    "    for e_lr in list_lr:\n",
    "        for e_l2 in list_l2:\n",
    "            n1 = FCN(e_model, epochs=1000000, save_term=100000, l2=e_l2, lr=e_lr)\n",
    "            n1.fit(x_train, y_train, x_val, y_val)\n",
    "            print(f\"model : {e_model}, lr:{e_lr}, l2:{e_l2}, best_acc = {np.max(n1.val_acc_log):>.8}\")\n",
    "            draw_acc(n1,True, f\"result/{n1.last_saved_time}_acc.png\", show=False)\n",
    "            draw_err(n1, True, f\"result/{n1.last_saved_time}_loss.png\", show=False)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
