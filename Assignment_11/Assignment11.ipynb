{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pulli\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\pulli\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.datasets import load_files\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "\n",
    "\n",
    "review_data = load_files(r\"movie_review\")\n",
    "X, y = review_data.data, review_data.target\n",
    "\n",
    "documents = []\n",
    "\n",
    "stemmer = WordNetLemmatizer()\n",
    "\n",
    "for sen in range(0, len(X)):\n",
    "    # Remove all the special characters\n",
    "    document = re.sub(r'\\W', ' ', str(X[sen]))\n",
    "    \n",
    "    # remove all single characters\n",
    "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "    \n",
    "    # Remove single characters from the start\n",
    "    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
    "    \n",
    "    # Substituting multiple spaces with single space\n",
    "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "    \n",
    "    # Removing prefixed 'b'\n",
    "    document = re.sub(r'^b\\s+', '', document)\n",
    "    \n",
    "    # Converting to Lowercase\n",
    "    document = document.lower()\n",
    "    \n",
    "    # Lemmatization\n",
    "    document = document.split()\n",
    "    document = [stemmer.lemmatize(word) for word in document]\n",
    "    document = ' '.join(document)\n",
    "    \n",
    "    documents.append(document)\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=1500, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))\n",
    "X = vectorizer.fit_transform(documents).toarray()\n",
    "\n",
    "tfidfconverter = TfidfTransformer()\n",
    "X = tfidfconverter.fit_transform(X).toarray()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    a = 1 / (1 + torch.exp(-z))\n",
    "    return a\n",
    "\n",
    "def softmax(z):\n",
    "    exp_z = torch.exp(z)\n",
    "    return exp_z / torch.sum(exp_z, axis=1).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN:\n",
    "    def __init__(self, architect, epochs=100, lr=0.1, l2=0, starting = 0, model_name = 'fcn'):\n",
    "        # parameters\n",
    "        self.w = []\n",
    "        self.b = []\n",
    "        self.architect = architect\n",
    "        self.initialize(architect)\n",
    "        \n",
    "        # for calculate\n",
    "        self.a = [0]*(len(self.w)+1)\n",
    "        self.dw = [0]*len(self.w)\n",
    "        self.db = [0]*len(self.w)\n",
    "        \n",
    "        # log\n",
    "        self.loss_log = []\n",
    "        self.acc_log = []\n",
    "        self.val_loss_log = []\n",
    "        self.val_acc_log = []\n",
    "        \n",
    "        # hyper parameters\n",
    "        self.start_lr = lr\n",
    "        self.lr = lr\n",
    "        self.l2 = l2\n",
    "        self.epochs = epochs\n",
    "        \n",
    "        # ect\n",
    "        self.starting = starting\n",
    "        self.model_path = 'model/'\n",
    "        self.model_name = model_name\n",
    "        self.last_saved_time = 0\n",
    "        np.random.seed(421)\n",
    "    \n",
    "    def initialize(self, architect):\n",
    "        for i in range(len(architect)-1):\n",
    "            self.w.append(torch.Tensor(np.random.normal(0, 1, (architect[i], architect[i+1]))).to(device))\n",
    "            self.b.append(torch.Tensor(np.zeros(architect[i+1])).to(device))\n",
    "    \n",
    "    def forpass(self, x):\n",
    "        z = x.t()\n",
    "        self.a[0] = z\n",
    "        for i in range(len(self.w)):\n",
    "            y = torch.mm(z, self.w[i]) + self.b[i]\n",
    "            z = sigmoid(y)\n",
    "            self.a[i+1] = z\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    def backprop(self, err):\n",
    "        m = len(self.a[0])\n",
    "        err_h = err\n",
    "        \n",
    "        for i in range(len(self.w)-1, 0, -1):\n",
    "            self.dw[i] = torch.mm(self.a[i].T, err_h)/ m\n",
    "            if i== len(self.w)-1:\n",
    "                self.db[i] = torch.sum(err_h) / m\n",
    "            else:\n",
    "                self.db[i] = torch.sum(err_h, axis=0) / m\n",
    "            \n",
    "            err_h = torch.mm(err_h, self.w[i].T ) * self.a[i] * ( 1 - self.a[i])\n",
    "    \n",
    "    def update(self, m):\n",
    "        for i in range(len(self.w)):\n",
    "            m = len(self.a[0])\n",
    "            self.dw[i] += self.l2 * self.w[i] / m\n",
    "            self.w[i] -= self.lr * self.dw[i]\n",
    "            self.b[i] -= self.lr * self.db[i]\n",
    "\n",
    "    def training(self, x, y):\n",
    "        m = len(x)\n",
    "        z = self.forpass(x)\n",
    "        a = softmax(z)\n",
    "        err = -(y - a)\n",
    "        self.backprop(err)\n",
    "        self.update(m)\n",
    "        \n",
    "        return a\n",
    "    \n",
    "    def fit(self, x, y, val_x, val_y):\n",
    "        m = len(x)\n",
    "        for k in range(self.epochs):\n",
    "            a = self.training(x, y)\n",
    "            a = torch.clamp(a, min=1e-10, max=1-1e-10)\n",
    "            \n",
    "            loss = torch.sum(-y*torch.log(a))\n",
    "            \n",
    "            z_v = self.forpass(x_val)\n",
    "            a_v = softmax(z_v)\n",
    "            a_v = torch.clamp(a_v, min=1e-10, max=1-1e-10)\n",
    "            \n",
    "            val_loss = torch.sum(-val_y*torch.log(a_v))\n",
    "            \n",
    "            l2_sum = 0\n",
    "            for i in range(len(self.w)):\n",
    "                l2_sum += self.l2 / 2 * torch.sum(self.w[i]**2)\n",
    "            \n",
    "            loss += l2_sum\n",
    "            val_loss += l2_sum\n",
    "            \n",
    "            acc = torch.argmax(a, axis=1) == torch.argmax(y, axis=1)\n",
    "            acc = torch.mean(acc.float())\n",
    "            val_acc = torch.argmax(a_v, axis=1) == torch.argmax(val_y, axis=1)\n",
    "            val_acc = torch.mean(val_acc.float())\n",
    "            \n",
    "            \n",
    "            self.loss_log.append(loss.item())\n",
    "            self.acc_log.append(acc.item())\n",
    "            self.val_loss_log.append(val_loss.item())\n",
    "            self.val_acc_log.append(val_acc.item())\n",
    "            \n",
    "            # decrease learning rate at each epoch\n",
    "            #self.lr -=  self.start_lr / (self.epochs) * 0.1\n",
    "\n",
    "        self.last_saved_time = int(time.time())\n",
    "        self.save_model(self.epochs+self.starting, f\"{self.model_name}_{self.last_saved_time}_{self.epochs+self.starting}_{np.max(self.val_acc_log):>.8}\"  + \".pt\")\n",
    "                \n",
    "                \n",
    "    def save_model(self, epoch, name):\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'acc' : self.acc_log,\n",
    "            'loss': self.loss_log,\n",
    "            'val_loss' : self.val_loss_log,\n",
    "            'val_acc' : self.val_acc_log,\n",
    "            'w' : self.w,\n",
    "            'b' : self.b,\n",
    "            'slr':self.start_lr,\n",
    "            'lr': self.lr,\n",
    "            'l2': self.l2,\n",
    "        }, self.model_path + name)\n",
    "    \n",
    "    def load_model(self, name, new_epoch):\n",
    "        saved_model = torch.load(self.model_path + name)\n",
    "        self.starting = saved_model['epoch']\n",
    "        self.start_lr = saved_model['slr']\n",
    "        self.lr = saved_model['lr']\n",
    "        self.l2 = saved_model['l2']\n",
    "        self.w = saved_model['w']\n",
    "        self.b = saved_model['b']\n",
    "        self.acc_log = saved_model['acc']\n",
    "        self.loss_log = saved_model['loss']\n",
    "        self.val_acc = saved_model['val_acc']\n",
    "        self.val_loss = saved_model['val_loss']\n",
    "        self.a = [0]*(len(self.w)+1)\n",
    "        self.dw = [0]*len(self.w)\n",
    "        self.db = [0]*len(self.w)\n",
    "        self.epochs = new_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_acc(fcn, save=False, name='', show=True):\n",
    "        plt.plot(np.squeeze(fcn.acc_log), color='b', label='train')\n",
    "        plt.plot(np.squeeze(fcn.val_acc_log), color='r', label='test')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('iterations ')\n",
    "        plt.legend()\n",
    "        plt.title(\"Learning rate =\" + str(fcn.start_lr)+\"  L2 =\" + str(fcn.l2) + \" model : \" + str(fcn.model_name))\n",
    "        if save:\n",
    "            plt.savefig(name)\n",
    "            plt.cla()\n",
    "        if show:\n",
    "            plt.show()\n",
    "        \n",
    "            \n",
    "        \n",
    "def draw_err(fcn, save=False, name='',show=True):\n",
    "        plt.plot(np.squeeze(fcn.loss_log), color='b', label='train')\n",
    "        plt.plot(np.squeeze(fcn.val_loss_log), color='r', label='test')\n",
    "        plt.ylabel('loss')            \n",
    "        plt.xlabel('iterations ')\n",
    "        plt.legend()\n",
    "        plt.title(\"Learning rate =\" + str(fcn.start_lr)+\"  L2 =\" + str(fcn.l2) + \" model : \" + str(fcn.model_name))\n",
    "        if save:\n",
    "            plt.savefig(name)\n",
    "            plt.cla()\n",
    "        if show:\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple = [1500, 750, 100, 2]\n",
    "n1 = FCN(simple, epochs=100, l2=0.005, lr = 0.05)\n",
    "n1.fit(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(X_train, y_train):\n",
    "    \n",
    "    \n",
    "classifier = train_classifier(X_train, y_train)\n",
    "y_pred_test = classifier.predict(X_test)\n",
    "y_pred_train = classifier.predict(X_train)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_train,y_pred_train))\n",
    "print(classification_report(y_train,y_pred_train))\n",
    "print(accuracy_score(y_train, y_pred_train))\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred_test))\n",
    "print(classification_report(y_test,y_pred_test))\n",
    "print(accuracy_score(y_test, y_pred_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(601, 1500)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[699,   0],\n",
       "       [  0, 702]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "confusion_matrix(y_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       699\n",
      "           1       1.00      1.00      1.00       702\n",
      "\n",
      "    accuracy                           1.00      1401\n",
      "   macro avg       1.00      1.00      1.00      1401\n",
      "weighted avg       1.00      1.00      1.00      1401\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
